import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from openai import OpenAI
import os
import json
from difflib import get_close_matches
import re

client = OpenAI(api_key="")  # ì‹¤ì œ í‚¤ë¡œ ëŒ€ì²´

# âœ… ê¸°ì¤€ ì¦ìƒ ë° ì—°ê´€ ì¦ìƒ ì •ì˜
cluster_symptoms = [
    "ê°ê¸°", "ë…ê°", "íë ´", "ê¸°ê´€ì§€ì—¼", "ì²œì‹", "ì•Œë ˆë¥´ê¸°ë¹„ì—¼", "ì¶•ë†ì¦", "íŽ¸ë„ì—¼", "ì¸í›„ì—¼", "ì¤‘ì´ì—¼",
    "ìœ„ì—¼", "ìœ„ì‹ë„ì—­ë¥˜", "ì†Œí™”ë¶ˆëŸ‰", "ìž¥ì—¼", "ë³€ë¹„", "ì„¤ì‚¬", "ê³¼ë¯¼ì„±ëŒ€ìž¥ì¦í›„êµ°", "ì¹˜í•µ", "ê°„ì—¼", "ì§€ë°©ê°„",
    "ë‹´ì„ì¦", "ìš”ë¡œê°ì—¼", "ë°©ê´‘ì—¼", "ì‹ ìš°ì‹ ì—¼", "ì‹ ìž¥ê²°ì„", "ê³ í˜ˆì••", "ì €í˜ˆì••", "ê³ ì§€í˜ˆì¦", "ë‹¹ë‡¨ë³‘", "ë¹ˆí˜ˆ",
    "ì‹¬ë¶€ì „", "í˜‘ì‹¬ì¦", "ì‹¬ê·¼ê²½ìƒ‰", "ì‹¬ê³„í•­ì§„", "ë‡Œì¡¸ì¤‘", "ì¹˜ë§¤", "ê°„ê²½ë³€", "ê°‘ìƒì„ ê¸°ëŠ¥ì €í•˜ì¦", "ê°‘ìƒì„ ê¸°ëŠ¥í•­ì§„ì¦",
    "ë¬´ë¦Žê´€ì ˆì—¼", "í‡´í–‰ì„±ë””ìŠ¤í¬", "ìš”í†µ", "ê²¬í†µ", "ê·¼ìœ¡í†µ", "ë¥˜ë§ˆí‹°ìŠ¤ê´€ì ˆì—¼", "í†µí’", "í”¼ë¶€ì—¼", "ì•„í† í”¼",
    "ë‘ë“œëŸ¬ê¸°", "ë¬´ì¢€", "ìŠµì§„", "ê²°ë§‰ì—¼", "ì•ˆêµ¬ê±´ì¡°ì¦", "ë°±ë‚´ìž¥", "ë…¹ë‚´ìž¥", "êµ¬ë‚´ì—¼", "êµ¬ê°•ê±´ì¡°ì¦",
    "ì¹˜í†µ", "ìž‡ëª¸ì—¼ì¦", "ë¹„ë§Œ", "ì‹ìš•ë¶€ì§„", "ë¶ˆë©´ì¦", "ì½”ê³¨ì´", "ìˆ˜ë©´ë¬´í˜¸í¡ì¦", "ìŠ¤íŠ¸ë ˆìŠ¤ìž¥ì• ", "ìš°ìš¸ì¦", "ë¶ˆì•ˆìž¥ì• ",
    "ê³µí™©ìž¥ì• ", "ì£¼ì˜ë ¥ê²°í•ê³¼ìž‰í–‰ë™ìž¥ì• ", "í‹±ìž¥ì• ", "íŽ¸ë‘í†µ", "ë‘í†µ", "í˜„ê¸°ì¦", "ì²­ê°ìž¥ì• ", "ì´ëª…",
    "í˜¸í¡ê³¤ëž€", "ê°€ìŠ´í†µì¦", "ë³µí†µ", "í‰í†µ", "ì˜¤í•œ", "ê³ ì—´", "ë°œì—´", "ë¬´ê¸°ë ¥", "í”¼ë¡œ",
    "ë©”ìŠ¤êº¼ì›€", "êµ¬í† ", "ì‹ì¤‘ë…", "íƒˆìˆ˜", "í™”ìƒ", "ê³¨ì ˆ", "íƒ€ë°•ìƒ", "ì—¼ì¢Œ", "ë¶€ì¢…",
    "ì†ë°œì €ë¦¼", "ê·¼ìœ¡ê²½ë ¨", "í”¼ë¶€ê±´ì¡°", "ë•€ìƒ˜ì§ˆí™˜", "ìƒë¦¬í†µ", "ìƒë¦¬ë¶ˆìˆœ", "ê°±ë…„ê¸°ìž¥ì• ", "ìž„ì‹ ì˜¤ì¡°", "ìœ ì‚°ì§•í›„",
    "ì €í˜ˆë‹¹", "ë§ì´ˆì‹ ê²½ë³‘ì¦","ìžìœ¨ì‹ ê²½ì‹¤ì¡°ì¦","ê¸°ì¹¨","ê°€ëž˜","ì¸í›„í†µ","ì½§ë¬¼","ì‹œì•¼ íë¦¼"
]

original_related_symptoms = {
    "ê°ê¸°": ["ê¸°ì¹¨", "ì½§ë¬¼", "ì˜¤í•œ", "ì¸í›„í†µ", "ë‘í†µ", "ë°œì—´"],
    "ê¸°ì¹¨": ["ê°€ëž˜","ê°ê¸°"],
    "ë…ê°": ["ê³ ì—´", "ê·¼ìœ¡í†µ", "ë‘í†µ", "ê¸°ì¹¨", "ì˜¤í•œ", "í”¼ë¡œ"],
    "íë ´": ["ê¸°ì¹¨", "ê°€ëž˜", "í˜¸í¡ê³¤ëž€", "ê³ ì—´", "í‰í†µ"],
    "ê¸°ê´€ì§€ì—¼": ["ê¸°ì¹¨", "ê°€ëž˜", "í‰í†µ", "ì¸í›„í†µ"],
    "ì²œì‹": ["í˜¸í¡ê³¤ëž€", "ê¸°ì¹¨", "ê°€ìŠ´í†µì¦", "ìŒ•ìŒ•ê±°ë¦¼"],
    "ì•Œë ˆë¥´ê¸°ë¹„ì—¼": ["ì½§ë¬¼", "ì½”ë§‰íž˜", "ìž¬ì±„ê¸°", "ëˆˆ ê°€ë ¤ì›€"],
    "ì¶•ë†ì¦": ["ë‘í†µ", "ì½§ë¬¼", "ì½”ë§‰íž˜", "ì–¼êµ´í†µì¦"],
    "íŽ¸ë„ì—¼": ["ëª©í†µì¦", "ë°œì—´", "ì‚¼í‚´ê³¤ëž€", "í”¼ë¡œ"],
    "ì¸í›„ì—¼": ["ëª©ì´ ì¹¼ì¹¼í•¨", "ì¸í›„í†µ", "ê¸°ì¹¨"],
    "ì¤‘ì´ì—¼": ["ê·€í†µì¦", "ë°œì—´", "ì²­ë ¥ì €í•˜", "í˜„ê¸°ì¦"],

    "ìœ„ì—¼": ["ë³µí†µ", "ë©”ìŠ¤êº¼ì›€", "ì‹ìš•ë¶€ì§„", "ì†ì“°ë¦¼"],
    "ì†Œí™”ë¶ˆëŸ‰": ["ë©”ìŠ¤êº¼ì›€"],
    "ìž¥ì—¼": ["ë³µí†µ", "ì„¤ì‚¬", "êµ¬í† ", "íƒˆìˆ˜"],
    "ë³€ë¹„": ["ë°°ë³€ê³¤ëž€", "ë³µí†µ"],
    "ì„¤ì‚¬": ["ë³µí†µ", "íƒˆìˆ˜", "êµ¬í† "],

    "ê³ í˜ˆì••": ["ë‘í†µ", "í˜„ê¸°ì¦", "ì‹¬ê³„í•­ì§„"],
    "ì €í˜ˆì••": ["ë¬´ê¸°ë ¥", "í”¼ë¡œ", "í˜„ê¸°ì¦"],
    "ê³ ì§€í˜ˆì¦": ["ê°€ìŠ´í†µì¦", "í˜„ê¸°ì¦"],
    "ë‹¹ë‡¨ë³‘": ["ìž¦ì€ ì†Œë³€", "ê°ˆì¦", "í”¼ë¡œ", "ì²´ì¤‘ê°ì†Œ", "ì†ë°œ ì €ë¦¼", "ë•€ìƒ˜ì§ˆí™˜", "ì‹œì•¼ íë¦¼"],
    "ì €í˜ˆë‹¹": ["ì†ë°œ ì €ë¦¼", "ë•€ìƒ˜ì§ˆí™˜", "ì‹œì•¼ íë¦¼", "í”¼ë¡œ", "ë‘í†µ"],
    "ë§ì´ˆì‹ ê²½ë³‘ì¦": ["ì†ë°œ ì €ë¦¼", "ê·¼ìœ¡ê²½ë ¨"],
    "ìžìœ¨ì‹ ê²½ì‹¤ì¡°ì¦": ["ì‹¬ê³„í•­ì§„", "í˜„ê¸°ì¦", "ë•€ìƒ˜ì§ˆí™˜"],
    "ë‘í†µ": ["íŽ¸ë‘í†µ", "í˜„ê¸°ì¦", "ëˆˆë¶€ì‹¬", "ë©”ìŠ¤êº¼ì›€"],
    "íŽ¸ë‘í†µ": ["ë‘í†µ", "íŽ¸ë‘í†µ"],

    "ìš”ë¡œê°ì—¼": ["ë°°ë‡¨í†µ", "ë¹ˆë‡¨", "í˜ˆë‡¨", "í•˜ë³µí†µ"],
    "ë°©ê´‘ì—¼": ["ë°°ë‡¨í†µ", "ìž”ë‡¨ê°", "ë¹ˆë‡¨"],

    "í”¼ë¡œ": ["ë¬´ê¸°ë ¥", "ë¶ˆë©´ì¦", "ì§‘ì¤‘ë ¥ ì €í•˜"],
    "ë¶ˆë©´ì¦": ["ìˆ˜ë©´ìž¥ì• ", "í”¼ë¡œ", "ìŠ¤íŠ¸ë ˆìŠ¤"],

    "ìš°ìš¸ì¦": ["ë¬´ê¸°ë ¥", "ì‹ìš•ë¶€ì§„", "ë¶ˆë©´ì¦", "ìš°ìš¸ì¦"],
    "ë¶ˆì•ˆìž¥ì• ": ["ì‹¬ê³„í•­ì§„", "ë¶ˆì•ˆ", "ê³µí¬ê°"],

    "ìƒë¦¬í†µ": ["ë³µí†µ", "ìš”í†µ", "í”¼ë¡œ", "ë©”ìŠ¤êº¼ì›€"],
    "ìƒë¦¬ë¶ˆìˆœ": ["ì£¼ê¸°ë³€í™”", "ë¬´ì›”ê²½", "ê³¼ë‹¤ì¶œí˜ˆ"]
}

# âœ… í‘œí˜„ ë§¤í•‘ ì‚¬ì „ (ë¹„í‘œì¤€ í‘œí˜„ â†’ í‘œì¤€ ì¦ìƒ)
symptom_aliases = {
  "ì†ì´ ë”ë¶€ë£©": "ì†Œí™”ë¶ˆëŸ‰ ",
  "ë°°ê°€ ë”ë¶€ë£©": "ì†Œí™”ë¶ˆëŸ‰ ",
  "ì†Œí™”ê°€ ì•ˆ ë¼": "ì†Œí™”ë¶ˆëŸ‰ ",
  "ì²´í–ˆ": "ì†Œí™”ë¶ˆëŸ‰ ",
  "ì†ì´ ìš¸ë ": "ë©”ìŠ¤êº¼ì›€ ",
  "í† í•  ê²ƒ": "êµ¬í†  ",
  "ë¨¸ë¦¬ê°€ ëµ": "ë‘í†µ ",
  "ì–´ì§€ëŸ¬": "í˜„ê¸°ì¦ ",
  "ëª¸ì´ ì‘¤ì…”": "ê·¼ìœ¡í†µ ",
  "ê°€ìŠ´ì´ ë‹µë‹µ": "í˜¸í¡ê³¤ëž€ ",
  "ìˆ¨ì‰¬ê¸° íž˜ë“¤": "í˜¸í¡ê³¤ëž€ ",
  "ìž…ë§›ì´ ì—†": "ì‹ìš•ë¶€ì§„ ",
  "ê¸°ìš´ì´ ì—†": "í”¼ë¡œ ",
  "ë§¥ì´ ì—†": "ë¬´ê¸°ë ¥ ",
  "ê°€ìŠ´ì´ ì² ë ": "ì‹¬ê³„í•­ì§„ ",
  "ì‹¬ìž¥ì´ í„°ì§ˆ ê²ƒ": "ì‹¬ê³„í•­ì§„ ",
  "ë¨¸ë¦¬ê°€ ê¹¨ì§ˆ ê²ƒ": "ë‘í†µ ",
  "í•˜ëŠ˜ì´ ë…¸ëž˜": "í˜„ê¸°ì¦ ",
  "í•˜ëŠ˜ì´ ë…¸ëž—ê²Œ": "í˜„ê¸°ì¦ ",
  "í—‰í—‰ê±°ë ¤": "í˜¸í¡ê³¤ëž€ ",
  "ìœ¼ìŠ¬ìœ¼ìŠ¬": "ì˜¤í•œ ",
  "í—ˆë¦¬ê°€ ëŠì–´ì§ˆ ê²ƒ": "ìš”í†µ ",
  "í†  ë‚˜ì™€": "êµ¬í†  ",
  "íŠ¸ë¦¼": "ì†Œí™”ë¶ˆëŸ‰ ",
  "ë°°ê°€ ìš°ë¦¬": "ë³µí†µ ",
  "ë•€ì´ ì¤„ì¤„": "ë•€ìƒ˜ì§ˆí™˜ ",
  "ì‹ì€ë•€": "ë•€ìƒ˜ì§ˆí™˜ ",
  "ì†ì´ ì“°ë ¤": "ì†ì“°ë¦¼ ",
  "ëª©ì´ ë”°ë”": "ì¸í›„í†µ ",
  "ëª©ì´ íƒ€ë“¤": "ê°ˆì¦ ",
  "ì¿¨ëŸ­ì¿¨ëŸ­": "ê¸°ì¹¨ ",
  "ì½œë¡ì½œë¡": "ê¸°ì¹¨ ",
  "ë’·ê³¨": "í›„ë‘í†µ ",
  "ì‹ ë¬¼": "ìœ„ì‚° ì—­ë¥˜ ",
  "ì†ì´ ì‹œ": "ìˆ˜ì¡±ëƒ‰ì¦ ",
  "ë°œì´ ì‹œ": "ìˆ˜ì¡±ëƒ‰ì¦ ",
  "ì†ë°œì´ ì‹œ": "ìˆ˜ì¡±ëƒ‰ì¦ ",
  "ì†ë°œì´ ì €": "ì†ë°œ ì €ë¦¼ ",
  "ì†ì´ ì €": "ì†ë°œ ì €ë¦¼ ",
  "ë°œì´ ì €": "ì†ë°œ ì €ë¦¼ ",
  "ì†ëì´ ì €": "ì†ë°œ ì €ë¦¼ ",
  "ëˆˆì´ íë¦¿": "ì‹œì•¼ íë¦¼ ",
  "ì´ˆì ì´ ì•ˆ ë§ž": "ì‹œì•¼ íë¦¼ ",
  "ëˆˆì´ ìž˜ ì•ˆ ë³´": "ì‹œì•¼ íë¦¼ ",
  "ë•€ì´ ë§Žì´": "ë•€ìƒ˜ì§ˆí™˜ "
}

# âœ… ë£¨íŠ¸ ì¦ìƒ ê°€ì¤‘ì¹˜ ì„¤ì •
root_boost = {
    # í˜¸í¡ê¸° ì§ˆí™˜
    "ê°ê¸°": 1.2,
    "íë ´": 1.1,
    "ì²œì‹": 1.1,

    # ì†Œí™”ê¸° ì§ˆí™˜
    "ìœ„ì—¼": 1.2,
    "ìž¥ì—¼": 1.1,
    "ì†Œí™”ë¶ˆëŸ‰": 1.05,

    # ìˆœí™˜ê¸°/ëŒ€ì‚¬
    "ê³ í˜ˆì••": 1.1,
    "ë‹¹ë‡¨ë³‘": 1.2,
    "ì‹¬ê·¼ê²½ìƒ‰": 1.1,

    # ì‹ ê²½/ì •ì‹ ê³¼
    "ë‘í†µ": 1.1,
    "íŽ¸ë‘í†µ": 1.05,
    "ìš°ìš¸ì¦": 1.2,
    "ë¶ˆì•ˆìž¥ì• ": 1.1,

    # ë¹„ë‡¨ê¸°
    "ìš”ë¡œê°ì—¼": 1.05,

    # ì—¬ì„± ì§ˆí™˜
    "ìƒë¦¬í†µ": 1.1,

    # ê°ì—¼ì„± or í”í•œ ì¦í›„êµ°
    "ë…ê°": 1.1,
    "ìž¥ì—¼": 1.1
}

# âœ… ìž„ë² ë”© í•¨ìˆ˜
def get_embedding(text):
    return np.array(client.embeddings.create(input=[text], model="text-embedding-3-large").data[0].embedding)

# âœ… ì¦ìƒ ìž„ë² ë”© íŒŒì¼ ë™ê¸°í™” (ì¶”ê°€/ì‚­ì œ/ì´ë¦„ë³€ê²½ ë°˜ì˜)
symptom_emb_file = "data/symptom_embeddings.json"
if os.path.exists(symptom_emb_file):
    with open(symptom_emb_file, "r", encoding="utf-8") as f:
        symptom_emb = json.load(f)
else:
    symptom_emb = {}

# [ìˆ˜ì •] ì´ë¦„ ë³€ê²½(ë§¤í•‘)ëœ ì¦ìƒ ì²˜ë¦¬
# 1. cluster_symptomsì— ì—†ëŠ” ê¸°ì¡´ ì¦ìƒ ì‚­ì œ
deleted = [k for k in symptom_emb if k not in cluster_symptoms]
for k in deleted:
    del symptom_emb[k]
# 2. ìƒˆë¡œ ì¶”ê°€ëœ ì¦ìƒ ì¶”ê°€
added = [sym for sym in cluster_symptoms if sym not in symptom_emb]
for sym in added:
    print("âœ¨ ìƒˆë¡œ ì¶”ê°€ëœ ì¦ìƒ:", sym)
    symptom_emb[sym] = get_embedding(sym).tolist()

if deleted:
    print("ðŸ—‘ï¸ ì‚­ì œëœ ì¦ìƒ:", deleted)

with open(symptom_emb_file, "w", encoding="utf-8") as f:
    json.dump(symptom_emb, f, ensure_ascii=False, indent=2)

# âœ… í´ëŸ¬ìŠ¤í„° ë³´ì •ìš© ë²¡í„° ìºì‹œë„ ë™ê¸°í™” (ì´ë¦„ ë³€ê²½ ë°˜ì˜)
cluster_map_file = "data/cluster_mappings.json"
if os.path.exists(cluster_map_file):
    with open(cluster_map_file, "r", encoding="utf-8") as f:
        cluster_map = json.load(f)
else:
    cluster_map = {}

all_cluster_keys = set(original_related_symptoms.keys())

# [ìˆ˜ì •] ì´ë¦„ ë³€ê²½(ë§¤í•‘)ëœ í´ëŸ¬ìŠ¤í„° ì²˜ë¦¬
# 1. ê´€ë ¨ ì¦ìƒì— ì—†ëŠ” ê¸°ì¡´ í´ëŸ¬ìŠ¤í„° ì‚­ì œ
cluster_deleted = [k for k in list(cluster_map.keys()) if k not in all_cluster_keys]
for k in cluster_deleted:
    print("ðŸ—‘ï¸ ì‚­ì œëœ í´ëŸ¬ìŠ¤í„°:", k)
    del cluster_map[k]

# 2. ìƒˆë¡œ ì¶”ê°€ëœ í´ëŸ¬ìŠ¤í„° ë° ê´€ë ¨ ì¦ìƒ ì¶”ê°€
for cluster, related in original_related_symptoms.items():
    if cluster not in cluster_map:
        cluster_map[cluster] = {}
    
    # ê¸°ì¡´ ì—°ê´€ ì¦ìƒë“¤ë„ symptom_aliasesë¥¼ í†µí•´ ë§¤í•‘
    mapped_related = set()
    for rel in related:
        mapped_rel = symptom_aliases.get(rel, rel)
        if mapped_rel in cluster_symptoms and mapped_rel != cluster:
            mapped_related.add(mapped_rel)
    
    # ë§¤í•‘ëœ ì—°ê´€ ì¦ìƒë“¤ë§Œ ìœ ì§€
    cluster_map[cluster] = {}
    for rel in mapped_related:
        # ì´ë¯¸ ìž„ë² ë”©ì´ ìžˆëŠ” ê²½ìš° ìž¬ì‚¬ìš©
        if rel in symptom_emb:
            #print("âœ… ì´ë¯¸ ìž„ë² ë”©ì´ ìžˆëŠ” ì¦ìƒ:", rel)
            cluster_map[cluster][rel] = symptom_emb[rel]
        else:
            print("âœ¨ ìƒˆë¡œ ì¶”ê°€ëœ ì¦ìƒ:", rel)
            cluster_map[cluster][rel] = get_embedding(rel).tolist()

if cluster_deleted:
    print("ðŸ—‘ï¸ ì‚­ì œëœ í´ëŸ¬ìŠ¤í„°:", cluster_deleted)

with open(cluster_map_file, "w", encoding="utf-8") as f:
    json.dump(cluster_map, f, ensure_ascii=False, indent=2)

# âœ… í‘œí˜„ ë§¤í•‘ ì‚¬ì „ ìžë™ ë™ê¸°í™”
expression_dict_file = "data/expression_mappings.json"
if os.path.exists(expression_dict_file):
    with open(expression_dict_file, "r", encoding="utf-8") as f:
        expression_dict = json.load(f)
else:
    expression_dict = {}


# [ìˆ˜ì •] ìƒˆë¡œ ì¶”ê°€ëœ ë¹„í‘œì¤€ í‘œí˜„ë§Œ ë°˜ì˜
for k, v in symptom_aliases.items():
    if k not in expression_dict and v in cluster_symptoms and k not in cluster_symptoms:
        print("âœ¨ ìƒˆë¡œ ì¶”ê°€ëœ í‘œí˜„:", k)
        expression_dict[k] = v

with open(expression_dict_file, "w", encoding="utf-8") as f:
    json.dump(expression_dict, f, ensure_ascii=False, indent=2)

# âœ… ë¹„í‘œì¤€ í‘œí˜„ ì •ë¦¬ ë° ìžê¸°ìžì‹  ì œê±°
related_symptoms = {}
for key, values in original_related_symptoms.items():
    # í‚¤(ì£¼ìš” ì¦ìƒ)ë„ symptom_aliasesë¥¼ í†µí•´ ë§¤í•‘
    #print("âœ… í‚¤:", key)
    mapped_key = symptom_aliases.get(key, key)
    if mapped_key not in cluster_symptoms:
        continue
        
    new_values = set()
    for v in values:
        # ê°’(ì—°ê´€ ì¦ìƒ)ë„ symptom_aliasesë¥¼ í†µí•´ ë§¤í•‘
        std = symptom_aliases.get(v, v)
        if std in cluster_symptoms and std != mapped_key:
            new_values.add(std)
    if new_values:
        #print("âœ… ê°’:", new_values)
        related_symptoms[mapped_key] = list(new_values)

# âœ… ì‚¬ìš©ìž ìž…ë ¥ ì²˜ë¦¬
user_input = input("\nðŸ“ ì¦ìƒì„ ìžì—°ì–´ë¡œ ìž…ë ¥í•˜ì„¸ìš”: ")


for expr, mapped in expression_dict.items():
    if expr in user_input:
        user_input = user_input.replace(expr, mapped)

# 2ï¸âƒ£ í¼ì§€ ë§¤ì¹­ìœ¼ë¡œ ì˜¤íƒ€ ë³´ì • ì ìš©
tokens = re.findall(r'[ê°€-íž£a-zA-Z0-9]+', user_input)
normalized_tokens = []
for token in tokens:
    close = get_close_matches(token, expression_dict.keys(), n=1, cutoff=0.6)
    if close:
        normalized_tokens.append(expression_dict[close[0]])
    else:
        normalized_tokens.append(token)


normalized_input = " ".join(normalized_tokens)
print(f"ðŸ”§ ì •ê·œí™”ëœ ìž…ë ¥: {normalized_input}")

# âœ… ì‚¬ìš©ìž ìž„ë² ë”© ìƒì„±
embedding_targets = [normalized_input.strip()]
if normalized_input in related_symptoms:
    embedding_targets += related_symptoms[normalized_input]
embedding_targets = list(set(embedding_targets))
embedding_vectors = [get_embedding(sym) for sym in embedding_targets]
user_emb = np.mean(embedding_vectors, axis=0).reshape(1, -1)

# âœ… ìœ ì‚¬ë„ ê³„ì‚°
symptom_array = np.array([symptom_emb[s] for s in cluster_symptoms])
base_similarities = cosine_similarity(user_emb, symptom_array)[0]

# âœ… ë³´ì • ë¡œì§: ê°ì‡ (log1p) ìœ ì§€ + ìž…ë ¥ ê²¹ì¹¨ ë³´ì • ê°•í™”
boosted_scores = []
input_length_penalty = 1 / (1 + 0.05 * len(tokens))

# âœ… ìž…ë ¥ì—ì„œ ì¦ìƒëª… ë‹¨ìœ„ë¡œ ì¶”ì¶œ (ì‚¬ì „ ê¸°ë°˜)
matched_symptoms = set()
for expr in cluster_symptoms:
    if expr in normalized_input:
        matched_symptoms.add(expr)
input_symptoms = matched_symptoms

for i, symptom in enumerate(cluster_symptoms):
    base_score = base_similarities[i] * input_length_penalty
    bonus = 0.0
    matched_rel_count = 0

    # âœ… ê´€ë ¨ ì¦ìƒê³¼ ìž…ë ¥ ì¦ìƒ ì§ì ‘ ê²¹ì¹  ê²½ìš°: ê°•í•œ ê°€ì¤‘
    overlap_count = 0
    if symptom in related_symptoms:
        overlap = set(related_symptoms[symptom]) & input_symptoms
        overlap_count = len(overlap)
        bonus += 0.3 * overlap_count
        if overlap_count == 2:
            #print(f"ðŸ” ì¤‘ì‹¬ ì§ˆí™˜ ì ìˆ˜: {base_score}")
            base_score *= 1.5  # ê°ê¸° ë“± ì¤‘ì‹¬ ì§ˆí™˜ ê°•ì¡°
        if overlap_count >= 3:
            #print(f"ðŸ” ì¤‘ì‹¬ ì§ˆí™˜ ì ìˆ˜: {base_score}")
            base_score *= 3.24  #ì¤‘ì‹¬ ì§ˆí™˜ ê°•ì¡°

    if symptom in cluster_map:
        for rel, rel_vec in cluster_map[symptom].items():
            rel_score = cosine_similarity(user_emb, np.array(rel_vec).reshape(1, -1))[0][0]
            if rel_score > 0.7:
                bonus += rel_score * 0.3  # ë¹„ë¡€ ë³´ì •
                matched_rel_count += 1
            elif rel_score > 0.5:
                bonus += rel_score * 0.2
                matched_rel_count += 1

    # ì—°ê´€ ì¦ìƒ ë‹¤ìˆ˜ í¬í•¨ ì‹œ ì¶”ê°€ ë³´ì • (ì„ í˜•)
    if matched_rel_count >= 2:
        bonus *= (1 + 0.1 * matched_rel_count)  # ì˜ˆ: 3ê°œ ì¼ì¹˜ ì‹œ 1.3ë°°

    # ë£¨íŠ¸ ì¦ìƒ ë³´ì •
    if symptom in root_boost:
        bonus *= root_boost[symptom]

    # âœ… ë‹¤ì¤‘ ì¦ìƒ ìž…ë ¥ ì‹œ, ë‹¨ì¼ ì¦ìƒ ê°€ì§€ì¹˜ê¸°(ë£¨í”„ ë‚´ì—ì„œ ë°”ë¡œ ì ìš©)
    if len(input_symptoms) >= 2 and symptom in input_symptoms:
        final_score *= 0.4  # ê°€ì§€ì¹˜ê¸° ë¹„ìœ¨(0.6)ì€ ì‹¤í—˜ì ìœ¼ë¡œ ì¡°ì •

    # ìµœì¢… ê°ì‡ ëœ ë³´ì • ì ìš©
    final_score = base_score * (1 + np.log1p(bonus))

    boosted_scores.append(final_score)
    
# âœ… ê²°ê³¼ ì¶œë ¥
sorted_indices = np.argsort(boosted_scores)[::-1]
print("\nðŸ” ìµœì¢… ìœ ì‚¬ ì¦ìƒ Top-5 (ë³´ì • ìœ ì‚¬ë„ ê¸°ë°˜):")
for rank in range(5):
    idx = sorted_indices[rank]
    print(f"{rank+1}. {cluster_symptoms[idx]} (ì ìˆ˜: {boosted_scores[idx]:.4f})")
    
    

def extract_top_symptoms(top_k: int = 5) -> list[str]:
    return [cluster_symptoms[i] for i in sorted_indices[:top_k]]

    
